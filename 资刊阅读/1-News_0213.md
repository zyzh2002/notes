# News @2/13/2023

## NASA and DARPA are working on a nuclear-powered rocket that could go to Mars [@TheWashingtonPost](https://www.washingtonpost.com/technology/2023/02/03/nuclear-rocket-darpa-nasa/)

When NASA’s Orion spacecraft returned to Earth from its trip around the moon last month, it was moving blazingly fast, nearly 25,000 mph, or 32 times the speed of sound.

On a trip to the moon, a mere 240,000 miles away, that’s a fine speed. For Mars, it’s painfully slow.

Using the technology NASA has, it could take some seven months to get to the Red Planet. That’s too long. Even astronauts get fussy when confined to a cramped space for months on end. And it’s dangerous. The radiation levels on a Mars mission could expose astronauts to radiation levels more than 100 times greater than on Earth.

If NASA’s going to get to Mars, it needs to find a way to get there much faster. Which is one of the reasons it said last week that it is partnering with the Pentagon’s Defense Advanced Research Projects Agency on development of nuclear propulsion technology.

“With the help of this new technology, astronauts could journey to and from deep space faster than ever — a major capability to prepare for crewed missions to Mars,” NASA Administrator Bill Nelson said in a statement. The goal, he said, is “to develop and demonstrate advanced nuclear thermal propulsion technology as soon as 2027.”

DARPA, the arm of the Defense Department that seeks to develop transformative technologies, has been working on the program since 2021, when it awarded three contracts for the first phase of the program to General Atomics, Lockheed Martin and Blue Origin, the space company founded by Jeff Bezos. (Bezos owns The Washington Post.) A nuclear-powered rocket would use a nuclear reactor to heat propellant to extreme temperatures before shooting the fuel through a nozzle to produce thrust.

Being able to move fast “is a core tenet of modern Department of Defense operations on land, at sea and in the air,” DARPA said in a statement at the time. “However, rapid maneuver in the space domain has traditionally been challenging because current electric and chemical space propulsion systems have drawbacks in thrust-to-weight and propellant efficiency.” In other words, traditional systems require too much fuel that burn at relatively inefficient levels.

The program is called DRACO, for Demonstration Rocket for Agile Cislunar (or in the vicinity of the moon) Operations.

Under NASA’S agreement with DARPA, the space agency will lead the development of the nuclear thermal engine while DARPA will work to develop the experimental spacecraft that would be propelled by the nuclear engine. The agencies hope they’ll be ready to demonstrate their work with a spaceflight in 2027.

NASA is also working with the Department of Energy on a separate project to develop a nuclear power plant that could be used on the moon and perhaps one day on Mars.

But getting to Mars is exceedingly difficult, and despite claims from NASA for years that it was gearing up to send astronauts there, the agency is nowhere close to achieving that goal.

One of the main obstacles is the distance. Earth and Mars are only on the same side of the sun every 26 months. But even at their closest points, a spacecraft would have to follow an elliptical orbit around the sun that, as Tory Bruno, the CEO of the United Launch Alliance, wrote in a recent essay, will require “a great sweeping arc of around 300 million miles to arrive.”

The path to Mars, he wrote, would require a far more efficient propulsion system with speeds that double Orion’s recent velocity. Nuclear power could provide that.

“Clearly, the faster we can complete the journey to Mars the better,” he wrote. “This means developing a much more efficient propulsion technology that could cut transit time by at least 50 percent, making the trip safer, and leaving more mass available for experiments and research gear.”

In an interview, Bruno said achieving a more efficient type of propulsion is not just about getting to space but “about transportation through space,” or moving through space from one destination to another. As space becomes a contested environment, developing a system that is far more efficient is something that the Pentagon and the U.S. Space Force have been focused on, especially as threats to satellites have grown.

Satellites usually stay in orbit over a fixed trajectory. Without the power, or propellant to maneuver, that makes them a bit like sitting ducks. But with a more efficient fuel like nuclear propulsion they could become more agile — and evasive. The need for spacecraft that can maneuver away from the enemy has become clear during the war in Ukraine.

“It’s clear that space is viewed as a critical enabler to both militaries [Russa and Ukraine],” Gen. Chance Saltzman, the chief of operations for the U.S. Space Force, said last week, according to Air and Space Forces Magazine. “Both sides have attacked [satellite communication] capabilities to degrade command and control, and there’s been a concerted effort to interfere with GPS to reduce its effectiveness in the region.”

As those systems grow, having nuclear propulsion — a far more efficient fuel than liquid chemicals — will be key, Bruno said.

“Because space is an ever-changing environment, there’s a need to relocate assets that we have, and certainly a need to extend their useful life,” he said.

The Pentagon is also searching for better ways to move “larger payloads into farther locations in cislunar space — the volume of space between the Earth and the moon,” DARPA said. But doing that, it said, “will require a leap-ahead in propulsion technology.”

## How ChatGPT Can Improve Education, Not Threaten it [@ScientificAmercian](https://www.scientificamerican.com/article/how-chatgpt-can-improve-education-not-threaten-it/)

> A professor explains why he is allowing students to incorporate ChatGPT into their writing process instead of banning the new technology

To read the news, the sanctity of everything from college application essays to graduate school tests to medical licensing exams is imperiled by easy access to advanced artificial intelligence like ChatGPT, the AI chatbot that can produce remarkably clear, long-form answers to complex questions. Educators in particular worry about students turning to ChatGPT to help them complete assignments. One proposed solution is to roll back the clock to the 20th century, making students write exam essays using pen and paper, without the use of any Internet-connected electronic devices. The University of California, Los Angeles, where I teach, is considering making it an honor code violation to use ChatGPT for taking an exam or writing a paper.

That’s the wrong approach. This semester, I am telling the students in my class at the UCLA School of Law that they are free to use ChatGPT in their writing assignments. The time when a person had to be a good writer to produce good writing ended in late 2022, and we need to adapt. Rather than banning students from using labor-saving and time-saving AI writing tools, we should teach students to use them ethically and productively.

To remain competitive throughout their careers, students need to learn how to prompt an AI writing tool to elicit worthwhile output and know how to evaluate its quality, accuracy and originality. They need to learn to compose well-organized, coherent essays involving a mix of AI-generated text and traditional writing. As professionals working into the 2060s and beyond, they will need to learn how to engage productively with AI systems, using them to both complement and enhance human creativity with the extraordinary power promised by mid-21st-century AI.

In addition to the sound pedagogical reasons for treating ChatGPT as an opportunity and not a threat, there are practical ones as well. It simply isn’t feasible to effectively ban access to this technology. Honor code or not, many students will be unable to resist the temptation to seek AI assistance with their writing. And how would an educational institution enforce a ChatGPT ban? While there are tools aimed at detecting text produced by AI, future versions of AI will get better at emulating human writing—including to the point of emulating the style of the particular person who is using it. In the resulting arms race, the AI writing tools will always be one step ahead of the tools to detect AI text.

Enforcement of a ChatGPT ban would also inevitably produce the injustice of false positives and false negatives. Some students who use ChatGPT despite a ban would, through luck or thanks to careful-enough editing of AI-generated text, avoid having their writing flagged as AI-assisted. Worse, some students would be falsely accused of using ChatGPT, triggering enormous stress and potentially leading to punishment for a wrong they did not commit.

And what of the argument that learning to write well provides benefits that go well beyond writing? Writing a good essay from scratch requires careful, often painstaking, thought about organization, flow and communication. Learning to write without AI does indeed promote focused, disciplined thinking. But learning to successfully combine unassisted and AI-assisted writing to create truly good essays also requires these qualities.

Writing is a craft worthy of enormous respect, one which few of us ever master. But most students don’t aspire to become professional writers. Instead, they are preparing for careers where they will write to further goals beyond the production of writing. As we do today, they will write to communicate, explain, convince, memorialize, request and persuade. AI writing tools, when properly used, will help them do those things better.

When I was a middle and high school student in the late 1970s and early 1980s, I was told that professional success required good “penmanship” and the ability to perform long division by hand. By the time I entered the professional workforce in the late 1980s, technology advances had rendered those skills obsolete. Education culture can be very slow to change, as evidenced by the fact that many schools today still force children to learn long division—a task they will never have to perform anywhere outside of school. With AI writing, educators should stay ahead of the technology curve, as opposed to lagging decades behind it.

The upshot: I am helping my students to prepare for a future in which AI is simply another technology tool as opposed to a novelty. I am also telling them that they are solely and fully responsible for the writing they turn in bearing their name. If it’s factually inaccurate, that’s on them. If it’s badly organized, that’s on them. If it’s stylistically or logically inconsistent, that’s on them. If it’s partially plagiarized, that means that they have committed plagiarism.

In short, I’m encouraging my students to become responsible, aware users of the AI technologies that will play a profoundly important role over the course of their careers. The AI writing, so to speak, is on the wall.

## I tried Microsoft’s new AI-powered Bing. Here’s what it’s like [@CNN Business](https://edition.cnn.com/2023/02/08/tech/microsoft-ai-bing-experience/index.html)

> Microsoft’s Bing search engine has never made much of a dent in Google’s dominance in the more than 13 years since it launched. Now the company is hoping some buzzy artificial intelligence can win converts.

Microsoft on Tuesday announced an updated version of Bing designed to combine the fun and convenience of OpenAI’s viral ChatGPT tool with the information from a search engine.

Beyond providing a list of relevant links like traditional search engines, the new Bing also creates written summaries of the search results, chats with users to answer additional questions about their query and can write emails or other compositions based on the results. With the new Bing, for example, users can create trip itineraries, compile weekly meal plans and ask the chatbot questions when shopping for a new TV.

This is the new era of search that Microsoft (MSFT) — which is investing billions of dollars in OpenAI — envisions, one where users are accompanied by a sort of “co-pilot” around the web to help them better synthesize information. The company is betting on the new technology to drive users to Bing, which had for years been an also-ran to Google Search. Microsoft (MSFT) also announced an updated version of its Edge web browser with the new Bing capabilities built in.

The event comes as the race to develop and deploy AI technology heats up in the tech sector. Google on Monday unveiled a new chatbot tool dubbed “Bard” in an apparent bid to keep pace with Microsoft and the success of ChatGPT. Baidu, the Chinese search engine, also said this week it plans to launch its own ChatGPT-style service.

The updated Bing and Edge launched to the public on a limited basis on Tuesday, and are set to roll out to millions of people for unlimited search queries in the coming weeks. I took Bing for a spin at a press event at Microsoft’s Redmond, Washington, headquarters Tuesday.

The tool provides the sort of immediate gratification we now expect from the internet — rather than clicking through a bunch of links to suss out the answer to a question, the new Bing will do that work for you. But it’s still early days for the technology, which Microsoft says is still evolving.

Satya Nadella, chief executive officer of Microsoft Corp., during the company's Ignite Spotlight event in Seoul, South Korea, on Tuesday, Nov. 15, 2022. Nadella gave a keynote speech at an event hosted by the company's Korean unit.
Microsoft unveils revamped Bing search engine using AI technology more powerful than ChatGPT
The homepage of the new Bing feels familiar: you can type a query into the search bar and it returns a list of links, images and other results like a typical search engine. But on the left side of the page are written summaries of the results, complete with annotations and links to the original information sources. The search field allows up to 2,000 characters, so users can type the way they’d talk, rather than having to think of the few correct search terms to use.

Users can also click over to a “chat” page on Bing, where a chatbot can answer additional questions about their queries.

I asked Bing to write me a five-day vegetarian meal plan. It returned a list of vegetarian meals for breakfast, lunch and dinner for Monday through Friday, such as oatmeal with fresh berries and lentil curry. I then asked it to write me a grocery list based on that meal plan, and it returned a list of all the items I’d need to buy organized by grocery store section.

Based on my request, the Bing chatbot also wrote me an email that I could send to my partner with that grocery list, complete with a “Hi Babe” greeting and “XOXO” closing. It’s not exactly how I’d normally write, but it could save me time by giving me a draft to edit and then copy and paste into an email, rather than having to start from scratch.

The generated portions of Bing have personality. When you ask the chatbot a question, it responds conversationally and sometimes with emojis, letting you know it’s happy to help or that it hopes you have fun on the trip you’re planning.

With the new Edge browser, I asked the tool to summarize one of my articles, and then turn that into a social media post the length of a short paragraph with a “casual” tone that I could share on Twitter or LinkedIn.

### An imperfect tool

The new Bing is built in partnership with OpenAI — the company behind ChatGPT in which Microsoft has invested billions — on a more advanced version of the technology underlying the viral chatbot tool. Still, the new Bing has some of the quirks that the public version of ChatGPT is known for. For example, the same query may return different responses each time it’s run; this is in part just how the tool works, and in part because it’s pulling the most updated search results each time it runs.

It also didn’t cooperate with some of my requests. After the first time it created a meal plan, grocery list and email with the list, I ran the same requests two more times. But the second and third time, it wouldn’t write the email, instead saying something like, “sorry, I can’t do that, but you can do it yourself using the information I provided!” The tool is also sensitive to the wording used in queries — a request to “create a vegetarian meal plan” provided information about how to start eating healthier, whereas “create a 5-day vegetarian meal plan” provided a detailed list of meals to eat each day.

Even next-gen search technology isn’t immune to basic flubs. I can imagine using the tool ahead of an upcoming local election, to learn about who is running for office in my area, what their positions are and how and when to vote. But when I asked the chatbot, “when is the next election in Kings County, NY?” it returned information about the November election last year.

The new Bing may also present some of the same concerns as ChatGPT, including for educators. I asked Bing’s chatbot to write me a 300-word essay about the major themes of the book “Pride and Prejudice” and, within less than a minute, it had pumped out 364 words on three major themes in the novel (although some of the text sounded a bit repetitive or wonky). Per my request, it then revised the essay as if it was written by a fifth grader.

The chatbot tool has feedback buttons so users can indicate whether its answers were helpful or not, and users can also chat directly with the tool to tell it when answers were incorrect or unhelpful, the company says.

“We know we won’t be able to answer every question every single time, … We also know we’ll make our share of mistakes, so we’ve added a quick feedback button at the top of every search, so you can give us feedback and we can learn,” Yusuf Mehdi, Microsoft’s vice president and consumer chief marketing officer, said in a presentation.

With some controversial search topics, it appears the new Bing chatbot simply refuses to engage. For example, I asked it, “Can you tell me why vaccines cause autism?” to see how it would react to a common medical misinformation claim, and it responded: “My apologies, I don’t know how to discuss this topic. You can try learning more about it on bing.com.” The same query on the main search page returned more standard search results, such as links to the CDC and the Wikipedia page for autism.

Likewise, it would not return a chatbot request for how to build a pipe bomb, instead saying in its answer, “Building a pipe bomb is a dangerous and illegal activity that can cause serious harm to yourself and others. Please do not attempt to do so.” However, one of the links provided in the annotation of its answer brought me to a YouTube video with apparent instructions for building a pipe bomb.

Microsoft says it has developed the tool in keeping with its existing responsible AI principles, and made efforts to avoid its potential misuse. Executives said the new Bing is trained in part by sample conversations mimicking bad actors who might want to exploit the tool.

“With a technology this powerful I also know that we have an even greater responsibility to make sure that it’s developed, deployed and used properly,” said responsible AI lead Sarah Bird.

